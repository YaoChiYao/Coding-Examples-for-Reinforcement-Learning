{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of greedy algorithm is going into suboptimal easily. To solve that, we can make agent randomly pick some arms that do not have biggest reward. It adds more exploration compared to the greedy algorithm. And we need to control the exploration to make sure converge.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 1. 2. 0. 0. 0.]\n",
      "[3 1 1 0 1]\n",
      "[4, 2, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "#denote disturb as the probability that not choose the arm with biggest reward \n",
    "#it is an array with length of T-m and goes down with time\n",
    "def Generate_Disturb(t):\n",
    "    disturb = [(i+2)**-1 for i in range(t)]\n",
    "    return disturb\n",
    "\n",
    "def Epsilon_GreedyAlgorithm(disturb, m, T):\n",
    "    #initialize policy\n",
    "    policy = np.zeros(T)\n",
    "\n",
    "    #randomly generate the bornoulli distribution for every bandit arm\n",
    "    p_values = [random.random() for _ in range(m)]\n",
    "    rewards = bernoulli.rvs(p_values, size=m)\n",
    "    trial_arm = [i for i in range(m)]\n",
    "    chosen_times = [1 for _ in range(m)]\n",
    "\n",
    "    policy[:m] = trial_arm\n",
    "    #choose the arm that maximizes the reward with probability 1-epsilon\n",
    "    #choose arm arbitrarily with the probability epsilon\n",
    "    for i in range(T - m):\n",
    "        if bernoulli.rvs(1-disturb[i]) == 1:\n",
    "            chosen_arm = np.argmax(rewards/chosen_times)\n",
    "            rewards[chosen_arm] += bernoulli.rvs(p_values[chosen_arm])\n",
    "            policy[m+i] = chosen_arm\n",
    "            chosen_times[chosen_arm] += 1\n",
    "        else:\n",
    "            chosen_arm = random.randint(0, m-1) \n",
    "            rewards[chosen_arm] += bernoulli.rvs(p_values[chosen_arm])\n",
    "            policy[m+i] = chosen_arm\n",
    "            chosen_times[chosen_arm] += 1\n",
    "    return policy, rewards, chosen_times\n",
    "disturb = Generate_Disturb(5)\n",
    "policy, rewards, chosen_times = Epsilon_GreedyAlgorithm(disturb, 5,10)\n",
    "print(policy)\n",
    "print(rewards)\n",
    "print(chosen_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
